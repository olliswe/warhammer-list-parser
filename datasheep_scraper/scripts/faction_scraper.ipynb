{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T12:29:45.351113Z",
     "start_time": "2025-09-16T12:28:57.327960Z"
    }
   },
   "source": [
    "# scrape_39kpro_all_factions.py\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import json\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "BASE = \"https://39k.pro/\"\n",
    "\n",
    "def chrome_driver(headless=True):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--window-size=1366,900\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                         \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                         \"Chrome/123.0.0.0 Safari/537.36\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def wait_main(driver, timeout=15):\n",
    "    WebDriverWait(driver, timeout).until(\n",
    "        EC.presence_of_element_located((By.TAG_NAME, \"main\"))\n",
    "    )\n",
    "\n",
    "def get_faction_links(driver):\n",
    "    driver.get(BASE)\n",
    "    # Wait for the nav list of factions to appear\n",
    "    WebDriverWait(driver, 15).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#navlinks a[href^='/faction/']\"))\n",
    "    )\n",
    "    links = driver.find_elements(By.CSS_SELECTOR, \"#navlinks a[href^='/faction/']\")\n",
    "    out = []\n",
    "    for a in links:\n",
    "        name = a.text.strip()\n",
    "        href = a.get_attribute(\"href\")\n",
    "        if not href:\n",
    "            # fallback to relative href\n",
    "            href = urljoin(BASE, a.get_attribute(\"href\"))\n",
    "        out.append((name, href))\n",
    "    # De-duplicate by href\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for name, href in out:\n",
    "        if href not in seen:\n",
    "            unique.append((name, href))\n",
    "            seen.add(href)\n",
    "    return unique\n",
    "\n",
    "def extract_rules(driver):\n",
    "    rules = []\n",
    "    # There can be multiple rule headers; expand each and read the adjacent content container\n",
    "    headers = driver.find_elements(By.CSS_SELECTOR, \".army_rule_header\")\n",
    "    for h in headers:\n",
    "        rule_name = h.text.strip()\n",
    "        # Click the container if possible (handles cases where header itself isn’t clickable)\n",
    "        try:\n",
    "            container = h.find_element(By.XPATH, \"./ancestor::div[contains(@class,'collapsible_header')]\")\n",
    "        except Exception:\n",
    "            container = h\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", container)\n",
    "            container.click()\n",
    "            time.sleep(0.25)  # small pause for animation/render\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # The content is the *immediate next sibling* of the collapsible_header\n",
    "        content_text = \"\"\n",
    "        try:\n",
    "            content_block = container.find_element(By.XPATH, \"following-sibling::div[1]\")\n",
    "            # collect all text nodes within, keeping simple line breaks\n",
    "            parts = []\n",
    "            for div in content_block.find_elements(By.XPATH, \".//div\"):\n",
    "                t = div.text.strip()\n",
    "                if t:\n",
    "                    parts.append(t)\n",
    "            content_text = \"\\n\".join(parts).strip() or content_block.text.strip()\n",
    "        except Exception:\n",
    "            content_text = \"\"\n",
    "\n",
    "        rules.append({\n",
    "            \"rules_name\": rule_name,\n",
    "            \"rules_content\": content_text\n",
    "        })\n",
    "    return rules\n",
    "\n",
    "def extract_list_after_h2(driver, header_text):\n",
    "    \"\"\"\n",
    "    Finds the UL right after an H2 with exact text (normalized) and returns list of (name, id) from <a>.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    try:\n",
    "        h2 = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, f\"//h2[normalize-space(text())='{header_text}']\"))\n",
    "        )\n",
    "        ul = h2.find_element(By.XPATH, \"following-sibling::*[self::ul][1]\")\n",
    "        links = ul.find_elements(By.CSS_SELECTOR, \"a[href]\")\n",
    "        for a in links:\n",
    "            name = a.text.strip()\n",
    "            href = a.get_attribute(\"href\") or a.get_attribute(\"data-href\") or \"\"\n",
    "            # If href is relative (e.g., /detachment/ID), keep only the last segment as the ID\n",
    "            ident = href.strip(\"/\").split(\"/\")[-1] if href else \"\"\n",
    "            items.append((name, ident))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return items\n",
    "\n",
    "def extract_faction(driver, url):\n",
    "    driver.get(url)\n",
    "    wait_main(driver)\n",
    "\n",
    "    # Faction title\n",
    "    try:\n",
    "        faction = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"main h1\"))\n",
    "        ).text.strip()\n",
    "    except Exception:\n",
    "        faction = \"\"\n",
    "\n",
    "    # Faction id from URL\n",
    "    faction_id = url.rstrip(\"/\").split(\"/\")[-1]\n",
    "\n",
    "    # Expand & read Rules\n",
    "    rules = extract_rules(driver)\n",
    "\n",
    "    # Detachments\n",
    "    det_pairs = extract_list_after_h2(driver, \"Detachments\")\n",
    "    detachments = [{\"detachment_name\": n, \"detachment_id\": i} for n, i in det_pairs]\n",
    "\n",
    "    # Datasheets\n",
    "    ds_pairs = extract_list_after_h2(driver, \"Datasheets\")\n",
    "    datasheets = [{\"datasheet_name\": n, \"datasheet_id\": i} for n, i in ds_pairs]\n",
    "\n",
    "    return {\n",
    "        \"faction\": faction,\n",
    "        \"faction_id\": faction_id,   # ✅ added\n",
    "        \"rules\": rules,\n",
    "        \"detachments\": detachments,\n",
    "        \"datasheets\": datasheets,\n",
    "        \"url\": url\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    driver = chrome_driver(headless=True)\n",
    "    try:\n",
    "        factions_index = get_faction_links(driver)\n",
    "        print(f\"Found {len(factions_index)} factions...\")\n",
    "        results = []\n",
    "\n",
    "        for idx, (name, href) in enumerate(factions_index, 1):\n",
    "            print(f\"[{idx}/{len(factions_index)}] Scraping: {name} -> {href}\")\n",
    "            try:\n",
    "                data = extract_faction(driver, href)\n",
    "                results.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"  !! Error on {href}: {e}\")\n",
    "            # Be polite to the site\n",
    "            time.sleep(0.4)\n",
    "\n",
    "        # Save to file\n",
    "        with open(\"factions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(\"Saved to factions.json\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 factions...\n",
      "[1/28] Scraping: Black Templars -> https://39k.pro/faction/oCfJYt7fR9g\n",
      "[2/28] Scraping: Blood Angels -> https://39k.pro/faction/a08Gx8RnzGo\n",
      "[3/28] Scraping: Dark Angels -> https://39k.pro/faction/cRLK-aDYBxk\n",
      "[4/28] Scraping: Space Wolves -> https://39k.pro/faction/hFK8CNsWTIU\n",
      "[5/28] Scraping: Adepta Sororitas -> https://39k.pro/faction/H-2eF-Lxbo4\n",
      "[6/28] Scraping: Adeptus Custodes -> https://39k.pro/faction/0xbccuVN0AM\n",
      "[7/28] Scraping: Adeptus Mechanicus -> https://39k.pro/faction/LWRg0FmeNEg\n",
      "[8/28] Scraping: Aeldari -> https://39k.pro/faction/Kaqw8u3NjVE\n",
      "[9/28] Scraping: Astra Militarum -> https://39k.pro/faction/B5x5FVeVo30\n",
      "[10/28] Scraping: Chaos Knights -> https://39k.pro/faction/iQVwBX1IUNA\n",
      "[11/28] Scraping: Chaos Space Marines -> https://39k.pro/faction/Vpbe4Na9krU\n",
      "[12/28] Scraping: Death Guard -> https://39k.pro/faction/BzYJcoeNhfE\n",
      "[13/28] Scraping: Emperor’s Children -> https://39k.pro/faction/wGFOtLxWY0k\n",
      "[14/28] Scraping: Genestealer Cults -> https://39k.pro/faction/7YwZZaUlhT4\n",
      "[15/28] Scraping: Grey Knights -> https://39k.pro/faction/9aSSlahg9l0\n",
      "[16/28] Scraping: Imperial Agents -> https://39k.pro/faction/3zadozqBeiQ\n",
      "[17/28] Scraping: Leagues of Votann -> https://39k.pro/faction/7RnIcWs4Ygw\n",
      "[18/28] Scraping: Necrons -> https://39k.pro/faction/L3CG_uWDC3c\n",
      "[19/28] Scraping: Orks -> https://39k.pro/faction/_qOplhrbEZs\n",
      "[20/28] Scraping: Space Marines -> https://39k.pro/faction/rmd5kyX0ZZ8\n",
      "[21/28] Scraping: Thousand Sons -> https://39k.pro/faction/QQpBBq_cr6k\n",
      "[22/28] Scraping: Tyranids -> https://39k.pro/faction/dmx8O4KuZ1M\n",
      "[23/28] Scraping: T’au Empire -> https://39k.pro/faction/B5D5HDWGX_M\n",
      "[24/28] Scraping: World Eaters -> https://39k.pro/faction/kd8l-oFCJQ0\n",
      "[25/28] Scraping: Chaos Daemons -> https://39k.pro/faction/jjeTuQ-AQDc\n",
      "[26/28] Scraping: Deathwatch -> https://39k.pro/faction/hw15VleUO6s\n",
      "[27/28] Scraping: Drukhari -> https://39k.pro/faction/9ab99Kg9p40\n",
      "[28/28] Scraping: Imperial Knights -> https://39k.pro/faction/Qk9srlBJebM\n",
      "Saved to factions.json\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "641bf846aaa3252d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
